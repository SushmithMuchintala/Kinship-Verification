{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff60aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Dec 19 16:41:39 2022\n",
    "\n",
    "@author: Sushmith\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "def get_batch_nmd(P, C, N):\n",
    "    h = N // 2\n",
    "    assert P.shape == C.shape\n",
    "    CropP = P[:, h:-h, h:-h, :]\n",
    "    Dists = np.empty((N*N, P.shape[0], P.shape[1]-N+1, P.shape[2]-N+1))\n",
    "    p = 0\n",
    "    for i in range(-h, h+1):\n",
    "        for j in range(-h, h+1):\n",
    "            i0, i1 = i+h, C.shape[1]+i-h\n",
    "            j0, j1 = j+h, C.shape[2]+j-h\n",
    "            CropC = C[:, i0:i1, j0:j1, :]\n",
    "            Dists[p, :, :, :] = np.sum(abs(CropP-CropC), axis=3)\n",
    "            p = p + 1\n",
    "    NMD3D = np.min(Dists, axis=0)\n",
    "    NMD = np.empty((NMD3D.shape[0],NMD3D.shape[1]*NMD3D.shape[2]))\n",
    "    for p in range(NMD3D.shape[0]):\n",
    "        NMD[p, :] = NMD3D[p].flatten()\n",
    "    return NMD\n",
    "\n",
    "def get_nmd(P, C, N):\n",
    "    assert P.shape == C.shape\n",
    "    NMD = np.empty((P.shape[0],(P.shape[1]-N+1)*(P.shape[2]-N+1)))\n",
    "    for batch in range(0, P.shape[0], batch_size):\n",
    "        size = min(batch_size, P.shape[0]-batch)\n",
    "        NMD[batch:batch+size, :] = get_batch_nmd(P[batch:batch+size, :, :, :], C[batch:batch+size, :, :, :], N)\n",
    "    return NMD\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from imageio import imread\n",
    "import scipy.io as sio\n",
    "from os.path import join\n",
    "\n",
    "def load_txt_pairs(filename):\n",
    "    metafile = open(filename, 'r')\n",
    "    metadata = metafile.read()\n",
    "    metafile.close()\n",
    "    metalines = [line for line in metadata.split('\\n') if len(line)>0]\n",
    "    str_pairs = [metaline.split(' ') for metaline in metalines]\n",
    "    pairs = [[int(pair[0]), int(pair[1]), pair[2], pair[3]] for pair in str_pairs]\n",
    "    return pairs\n",
    "\n",
    "def load_mat_pairs(filename):\n",
    "    meta = sio.loadmat(filename)\n",
    "    pairs = []\n",
    "    for p in meta['pairs']:\n",
    "        pairs.append([p[0][0][0], p[1][0][0], p[2][0], p[3][0]])\n",
    "    return pairs\n",
    "\n",
    "def get_image_dirs(rootdir, dataset, subset):\n",
    "    PrefixToDir={'fd':'father-dau','fs':'father-son','md':'mother-dau','ms':'mother-son'}\n",
    "    if dataset[:10]=='KinFaceW-I':\n",
    "        same_dir = join(rootdir, dataset, 'images', PrefixToDir[subset])\n",
    "        return (same_dir, same_dir)\n",
    "    if dataset=='CornellKinFace':\n",
    "        parents_dir = join(rootdir, dataset, 'Parents')\n",
    "        children_dir = join(rootdir, dataset, 'Children')\n",
    "        return (parents_dir, children_dir)\n",
    "    return None\n",
    "\n",
    "def load_pairs(rootdir, dataset, subset):\n",
    "    if dataset=='KinFaceW-I' or dataset=='KinFaceW-II':\n",
    "        return load_mat_pairs(join(rootdir, dataset, 'meta_data', subset + '_pairs.mat'))\n",
    "    if dataset=='CornellKinFace':\n",
    "        return load_txt_pairs(join(rootdir, dataset, 'cornell-meta.txt'))\n",
    "    return None\n",
    "\n",
    "def load_fold(rootdir, dataset, subset, fold):\n",
    "    pairs = load_pairs(rootdir, dataset, subset)\n",
    "    image_dirs = get_image_dirs(rootdir, dataset, subset)\n",
    "    P0, C0, K0 = [], [], []\n",
    "    P1, C1, K1 = [], [], []\n",
    "    for p in pairs:\n",
    "        pImg = imread(join(image_dirs[0], p[2])) / 255\n",
    "        cImg = imread(join(image_dirs[1], p[3])) / 255\n",
    "        if p[0] == fold:\n",
    "            P1.append(pImg)\n",
    "            C1.append(cImg)\n",
    "            K1.append(p[1])\n",
    "        else:\n",
    "            P0.append(pImg)\n",
    "            C0.append(cImg)\n",
    "            K0.append(p[1])\n",
    "    return ((np.array(P0), np.array(C0), np.array(K0)), (np.array(P1), np.array(C1), np.array(K1)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "\n",
    "rootdir = 'C:/Users/Bhargava/Desktop/kinface'\n",
    "\n",
    "datasets = [\n",
    "            ('KinFaceW-I', 'fs', 5),\n",
    "            ('KinFaceW-I', 'fd', 5),\n",
    "            ('KinFaceW-I', 'ms', 5),\n",
    "            ('KinFaceW-I', 'md', 5),\n",
    "            ('KinFaceW-II', 'fs', 5),\n",
    "            ('KinFaceW-II', 'fd', 5),\n",
    "            ('KinFaceW-II', 'ms', 5),\n",
    "            ('KinFaceW-II', 'md', 5)]\n",
    "\n",
    "nu_values = np.arange(0.05, 1.0, 0.05)\n",
    "max_depth_values = [max_depth for max_depth in range(10, 16)]\n",
    "n_estimators_values = [n_estimators for n_estimators in range(1, 6)]\n",
    "for (dataset, kinship, n_fold) in datasets:\n",
    "    print(dataset, kinship)\n",
    "    svm_accu_grid = np.zeros(len(nu_values), dtype=np.float32)\n",
    "    rdf_accu_grid = np.zeros((len(max_depth_values), len(n_estimators_values)), dtype=np.float32)\n",
    "    for fold in range(n_fold):\n",
    "        ((P0, C0, K0), (P1, C1, K1)) = load_fold(rootdir, dataset, kinship, fold+1)\n",
    "\n",
    "        NMD0 = get_nmd(P0, C0, 15)\n",
    "        NMD1 = get_nmd(P1, C1, 15)\n",
    "\n",
    "\n",
    "        for i, nu in enumerate(nu_values):\n",
    "            model = svm.NuSVC(nu=nu, kernel=\"rbf\", verbose=False, gamma=\"auto\")\n",
    "            model.fit(NMD0, K0)\n",
    "            accuracy = model.score(NMD1, K1)\n",
    "            svm_accu_grid[i] = svm_accu_grid[i] + accuracy\n",
    "            \n",
    "        for i, max_depth in enumerate(max_depth_values):\n",
    "            for j, n_estimators in enumerate(n_estimators_values):\n",
    "                best_accu = 0.0\n",
    "                for _ in range(5):\n",
    "                    model = ensemble.RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=1)\n",
    "                    model.fit(NMD0, K0)\n",
    "                    accuracy = model.score(NMD1, K1)\n",
    "                    if accuracy > best_accu:\n",
    "                        best_accu = accuracy\n",
    "                rdf_accu_grid[i, j] = rdf_accu_grid[i, j] + best_accu\n",
    "\n",
    "    best_nu = 0\n",
    "    best_accu = 0\n",
    "    for i, nu in enumerate(nu_values):\n",
    "        if svm_accu_grid[i] > best_accu:\n",
    "            best_accu = svm_accu_grid[i]\n",
    "            best_nu = nu\n",
    "    \n",
    "    print('SVM: %.02f%% [nu: %g]'%(100*best_accu/n_fold, best_nu))\n",
    "    \n",
    "    best_d = 0\n",
    "    best_n = 0\n",
    "    best_a = 0\n",
    "    for i, max_depth in enumerate(max_depth_values):\n",
    "        for j, n_estimators in enumerate(n_estimators_values):\n",
    "            if rdf_accu_grid[i, j]>best_a:\n",
    "                best_d = max_depth\n",
    "                best_n = n_estimators\n",
    "                best_a = rdf_accu_grid[i, j]\n",
    "    \n",
    "    print('RandomForest: %.02f%% [max_depth: %d] [n_estimators: %d]'%(100*best_a/n_fold, best_d, best_n))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
